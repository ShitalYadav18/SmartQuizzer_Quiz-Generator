# ğŸ§  SmartQuizzer â€“ Adaptive AI-Based Quiz Generator

SmartQuizzer is an **AI-powered quiz generation system** built using **Python and Streamlit**.  
The application analyzes study materials (PDF/Text), automatically generates quiz questions using **Large Language Models (LLMs)**, and provides difficulty-aware quizzes with performance insights. 

This project was developed as part of an **Internship Project**, focusing on practical implementation of **AI, NLP, and learning analytics**. 

---

## ğŸ“Œ Project Description

Traditional quizzes are static and often fail to adapt to a learnerâ€™s understanding.  
**SmartQuizzer** addresses this by creating a more **personalized assessment experience**, where questions are generated from the userâ€™s own study material and tagged with difficulty levels. 

The system combines **AI-based question generation**, **difficulty classification**, and **performance analytics** within an interactive **Streamlit web application**. 

---

## ğŸ¯ Internship Objectives

- Implement AI-driven quiz generation using Python and LLMs  
- Apply NLP concepts (text extraction, cleaning, prompt design) to real study material  
- Design and implement a difficulty-aware quiz experience  
- Build an end-to-end Streamlit-based application with analytics and clean UI [file:43]

---

## âœ¨ Features

- ğŸ“„ Upload **PDF / Text** study materials  
- ğŸ¤– AI-generated quiz questions:  
- Multiple-choice questions (MCQ)  
- True/False and short-answer style questions (depending on LLM output and prompts)  
- ğŸ§  Difficulty labels for each question (Easy / Medium / Hard)  
- ğŸ“ Quiz interface with timer, question navigation, and inline feedback  
- ğŸ“Š Performance analytics: score, accuracy, difficulty progression, topic-wise performance  
- ğŸ’¾ Local data storage using JSON for generated questions and quiz attempts  
- ğŸ–¥ Clean, minimal, and interactive Streamlit UI suitable for internship evaluation 

---

## ğŸ›  Tech Stack

- **Programming Language:** Python  
- **Web Framework:** Streamlit  
- **AI / NLP:**  
  - Large Language Model: *Meta-Llama-3-8B-Instruct* via Hugging Face Inference API  
  - Prompt Engineering for question generation and difficulty classification  
- **Data Processing:** Python text processing utilities, basic Pandas in analytics  
- **Visualization:** Plotly line and bar charts  
- **Storage:** Local JSON file (`data/questions.json`) for questions and quiz history 

---

## ğŸ§© Application Workflow

### 1ï¸âƒ£ Document Upload & Text Extraction
- User uploads a PDF file containing study material  
- Text is extracted and cleaned (removing noise and formatting) to prepare it for the LLM [file:43]

### 2ï¸âƒ£ AI Content Understanding & Question Generation
- A structured prompt is sent to the LLM asking it to generate questions in **valid JSON format**  
- Each generated item contains fields such as `question`, `answer`, `distractors`, `difficulty`, `topic`, and `type` [file:43]  
- A post-processing step removes clearly invalid or mismatched questions

### 3ï¸âƒ£ Difficulty Tagging
- Questions are assigned difficulty labels such as **easy**, **medium**, or **hard** based on their content  
- These labels are later used in analytics and can be extended to drive adaptive logic 

### 4ï¸âƒ£ Quiz Experience
  - The user starts a quiz from the generated question set in the **Quiz** tab  
  - For each question, the app:
  - Displays the question text, topic, and difficulty  
  - Presents shuffled answer options (correct answer + distractors)  
  - Records correctness and response time on submission

### 5ï¸âƒ£ Analytics & Feedback
  - In the **Analytics** tab, the app computes and visualizes:
  - Total score and accuracy  
  - Difficulty progression over the attempted questions  
  - Topic-wise accuracy and weak topics  
  - A recommendation message is generated based on overall performance (revise basics, focus on medium topics, or attempt more difficult questions) 

---

## ğŸ“‚ Project Structure

SmartQuizzer/
â”‚
â”œâ”€â”€ app.py
â”‚   â””â”€â”€ Main Streamlit application entry point
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ question_generator.py
â”‚   â”‚   â””â”€â”€ AI-based quiz question generation logic
â”‚   â”‚
â”‚   â”œâ”€â”€ difficulty_classifier.py
â”‚   â”‚   â””â”€â”€ Classifies questions into Easy / Medium / Hard
â”‚   â”‚
â”‚   â””â”€â”€ adaptive_engine.py
â”‚       â””â”€â”€ Adaptive logic to adjust quiz difficulty based on user performance
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ analytics.py
â”‚   â”‚   â””â”€â”€ Score calculation, accuracy, topic-wise & difficulty analysis
â”‚   â”‚
â”‚   â””â”€â”€ storage.py
â”‚       â””â”€â”€ Handles reading/writing questions and results to JSON storage
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ text_extraction.py
â”‚   â”‚   â””â”€â”€ PDF/text extraction and preprocessing utilities
â”‚   â”‚
â”‚   â””â”€â”€ prompts.py
â”‚       â””â”€â”€ Prompt templates for LLM-based question generation and classification
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ questions.json
â”‚       â””â”€â”€ Stores generated questions (created at runtime)
â”‚
â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ List of required Python dependencies
â”‚
â””â”€â”€ README.md
    â””â”€â”€ Project documentation



---

## ğŸ“¥ Example Question Object

The LLM is instructed to return questions in JSON objects like the following:
{
"question": "What does AI simulate?",
"answer": "Human intelligence",
"distractors": [
"Machine behavior",
"Animal instincts",
"Natural processes"
],
"difficulty": "easy",
"topic": "Artificial Intelligence",
"type": "mcq"
}

This format allows the app to automatically build MCQ options, tag difficulty, and group analytics by topic. 

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Clone the Repository
### 2ï¸âƒ£ (Optional) Create Virtual Environment
### 3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

### 4ï¸âƒ£ Set Up LLM API Access

- Create a Hugging Face access token and set it as an environment variable:  
  - `HF_TOKEN`  
- The app uses this token to call the **Meta-Llama-3-8B-Instruct** model for question generation and difficulty classification.

### 5ï¸âƒ£ Run the Streamlit Application
python -m streamlit run app.py


- Open the local URL shown in the terminal .  
- Use the **Upload & Generate** tab to upload a PDF and generate questions.  
- Switch to the **Quiz** tab to attempt the quiz.  
- View performance in the **Analytics** tab.

---

## ğŸ“Œ Future Enhancements

- Fully adaptive quiz path that changes difficulty based on recent answers in real time  
- Support for additional input formats (multiple PDFs, plain text, URLs)  
- Persistent storage using MongoDB instead of local JSON files  
- Exportable reports for learners or teachers (PDF/CSV dashboards)


